## Simple word tokenisation in Python

A simple set of fuctions that explore different ways to tokenise a document. Includes csv and regulare text tokenisation. PDF and other formats will be added soon. 

Note: this is not designed to replace NLTK, and use of NLTK's power is highly recommended. There is a lot of reinventing the wheel in these functions but they have been done mainly for fun and a quick look at how one would roll out their own tokenisation methods if NLTK didn;t exist. 

## Getting Started

I've tried to make these functions as 'plug-and-play''able as possible. Their also very easy to edit for those looking personalise for their own use. 


## Contents

tonkenisation.py

- file and csv to term split
- csv to line split
- unique terms in file
- remove punctuation 
- find words begining with capitals
- remove stop words



open_files.py 

- an interface function that opens files based on file format 
 


classes.py

- contains class version of all the above for oop. 